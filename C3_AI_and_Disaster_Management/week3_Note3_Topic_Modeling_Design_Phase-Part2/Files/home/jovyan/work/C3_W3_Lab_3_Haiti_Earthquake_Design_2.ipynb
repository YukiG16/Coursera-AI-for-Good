{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling: Design Phase - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will perform topic modeling by using a technique known as [Latent Dirichlet Allocation](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2) (LDA for short). Then, you will quantitatively compare the different models using a metric suited to measure the coherence of the topics generated.\n",
    "\n",
    "\n",
    "The steps you will complete in this lab are:\n",
    "1. Import Python packages\n",
    "2. Load the dataset\n",
    "3. Represent the data as Bag-of-Words\n",
    "4. Get a base LDA model\n",
    "5. Introducing the Coherence Score Metric\n",
    "6. Topic Modeling with LDA\n",
    "7. Select and evaluate the final LDA model\n",
    "8. Removing additional words (optional)\n",
    "\n",
    "**Note:** In all other case studies in this specialization, you have worked with examples of supervised learning, where you trained a model to learn the mapping from and input A to an output B. In this lab, you'll be developing an unsupervised learning model, which is to say, there are no labels or explicit right answers to train on. Your model will be looking for statistical similarities between the text of different messages in order to group them into topics. This sort of task is common in unsupervised learning projects, where you're often attempting to discover relationships or patterns in your data and draw inferences based on those patterns or relationships.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Python packages\n",
    "\n",
    "Run the next cell to import that Python packages you'll need for this lab.\n",
    "\n",
    "Note the `import utils` line. This line imports the functions that were specifically written for this lab. If you want to look at what these functions are, go to `File -> Open...` and open the `utils.py` file to have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from termcolor import colored\n",
    "import random\n",
    "import gensim\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "print('All packages imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the dataset\n",
    "\n",
    "Begin by loading in the cleaned dataframe from the last ungraded lab (that is saved in a `.pkl` file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiti_df = pd.read_pickle(\"./data/haiti_df_processed.pkl\")\n",
    "\n",
    "haiti_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Represent the data as Bag-of-Words\n",
    "\n",
    "Now you will convert the messages in the dataset into their BOW representation and generate other useful information such as a list containing all words in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the messages in the dataset\n",
    "corpus = haiti_df.message_tokens\n",
    "\n",
    "# Create the dictionary\n",
    "corpus_dictionary = gensim.corpora.Dictionary(corpus)\n",
    "\n",
    "# Filter out words that occur less than 5 times overall\n",
    "corpus_dictionary.filter_extremes(no_below=5)\n",
    "\n",
    "# Create a bag of words out of the full corpus\n",
    "corpus_bow = [corpus_dictionary.doc2bow(doc) for doc in corpus]\n",
    "\n",
    "# All words in the dictionary\n",
    "all_words = list(corpus_dictionary.values())\n",
    "\n",
    "print(f\"Dictionary contains a total of {len(all_words)} unique words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get a base LDA model\n",
    "\n",
    "There are several algorithms to perform topic modeling, as well as several Python libraries for this purpose. In this section you will perform topic modeling using Latent Dirichlet Allocation (LDA) with Gensim and pyLDAvis (for visualization). The three methods and libraries you will use are:\n",
    "\n",
    "Latent Dirichlet Allocation (LDA) is a generative probabilistic topic model that aims to uncover latent (or hidden) topics from a corpus. The corpus in this case is the collection of processed and tokenized messages. After topic modeling, each document is represented by a distribution over the topics that were found in the entire corpus.\n",
    "\n",
    "To interact with the LDA models you will be using the amazing library [Gensim](https://github.com/RaRe-Technologies/gensim). This library provides a lot of features for performing various NLP-related tasks. In fact, you already used it at the beginning of the lab to generate the BOW representation of the corpus.\n",
    "\n",
    "To train a LDA model on a corpus you can use the [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) class. In the next cell you will use it to train the model (it is abstracted in the `utils.train_lda_model` fumction) on the corpus data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 2\n",
    "lda_2_topics = utils.train_lda_model(num_topics=num_topics, corpus_bow=corpus_bow, corpus=corpus, corpus_dictionary=corpus_dictionary)\n",
    "utils.plot_top_words_lda(num_topics, lda_2_topics.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Introducing the Coherence Score Metric\n",
    "\n",
    "A common metric to compare models that aim at capturing topics from a corpus is the `coherence score`. This metric arises from the idea that \"a set of statements or facts are said to be coherent if they support each other\". This quote is taken from the paper [Exploring the Space of Topic Coherence Measures](https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf), in case you want to look into the details on this subject.\n",
    "\n",
    "A nice and simple explanation can be also found here:\n",
    "\n",
    "- [Understanding Topic Coherence Measures](https://towardsdatascience.com/understanding-topic-coherence-measures-4aa41339634c)\n",
    "\n",
    "More resources:\n",
    "\n",
    "- [Evaluating topic coherence measures](https://mimno.infosci.cornell.edu/nips2013ws/nips2013tm_submission_7.pdf)\n",
    "\n",
    "To compute this metric the `compute_coherence_score` function is used. This function uses Gensim's [CoherenceModel](https://radimrehurek.com/gensim/models/coherencemodel.html) class to compute the score for any given list of topics and corpus.\n",
    "\n",
    "**This metric is defined in such a way that values closer to 0 reflect a greater coherence**. \n",
    "\n",
    "To test it you will use two examples. One has the actual 10 top words for the topics (taken from the model) and the other is a random collection of words from the corpus. Notice that both examples have two lists of words which means that they simulate having two topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_top_words = utils.get_top_words_lda(num_topics, lda_2_topics.model, num_words=10)\n",
    "\n",
    "random_topics = [\n",
    "    random.sample(all_words, 10),\n",
    "    random.sample(all_words, 10),    \n",
    "]\n",
    "\n",
    "print(f\"Top words:\")\n",
    "for word_list in real_top_words:\n",
    "    print(f\"    {word_list}\")\n",
    "print(f\"Coherence score for the text using calculated topics is: {utils.compute_coherence_score(real_top_words, dictionary=corpus_dictionary, texts=corpus.values, corpus=corpus_bow):.3f}\\n\")\n",
    "\n",
    "print(f\"Random words:\")\n",
    "for word_list in random_topics:\n",
    "    print(f\"    {word_list}\")\n",
    "print(f\"Coherence score for the text using random topics is: {utils.compute_coherence_score(random_topics, dictionary=corpus_dictionary, texts=corpus.values, corpus=corpus_bow):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the previous cell multiple times you will get a different score for the random words (as different words are sampled with each run) but the score should always be around -20.\n",
    "\n",
    "As you would expect, there is a significant difference between actual top words of a topic and random words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Topic Modeling with LDA\n",
    "### 6.1 Computing models with different number of topics\n",
    "\n",
    "Now that you have a way to compare the coherence of a collection of words, you can use this to measure the performance of LDA topic modeling algorithms by evaluating the coherence of the top words of each topic.\n",
    "You will now compute the coherence score for the LDA models ranging from 2 to 6 topics. But first you have to train the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of topics\n",
    "max_number_of_topics = 6\n",
    "n_topics_range = range(2, max_number_of_topics + 1)\n",
    "\n",
    "# Dictionary to save trained models\n",
    "LDA_models = {}\n",
    "print(f\"Training LDA models from 2 to {max_number_of_topics} topics\")\n",
    "\n",
    "# For number of topics ranging from 2 to max_number_of_topics\n",
    "for i in n_topics_range:\n",
    "    # Save model\n",
    "    LDA_models[i] = utils.train_lda_model(num_topics=i, corpus_bow=corpus_bow, corpus=corpus, corpus_dictionary=corpus_dictionary) # Training all models takes around 2 mins\n",
    "    print(f\"Successfully trained LDA model on {i} topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Explore top words for different number of topics\n",
    "\n",
    "The coherence score metric is not perfect and within the subject of topic modeling there is no labeled ground truth, it all depends on what you are trying to accomplish. Have a look at the top words of each of the topics for models trained for different number of topics. While you can observe the coherence score as one metric of performance for different models, also look closely to get a sense of how human interpretation comes into this form of modeling, namely, despite whatever the coherence score says, can you get a sense of which models are producing more clearly relevant topics? Human interpretability is a key component of topic modeling in this way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.top_words_plot(LDA_models, max_number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Compare coherence scores\n",
    "\n",
    "Now compute the coherence score for each model. Create a plot so it is easier to visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save coherence scores in a list\n",
    "coherence_scores_lda = [LDA_models[i].coherence_score for i in n_topics_range]\n",
    "\n",
    "# plot coherence score as a function of number of topics\n",
    "utils.plot_coherences_lda(n_topics_range, coherence_scores_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Select and evaluate the final LDA model\n",
    "According to the plot above, the optimal mumber of Topics is two (this may vary if you choose different words to exclude - see step 8). So you can select the model with two topics as your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 2\n",
    "\n",
    "# Select the model from the trained models\n",
    "lda_model_final = LDA_models[num_topics]\n",
    "\n",
    "# Plot the top ten words for the selected model again\n",
    "utils.plot_top_words_lda(num_topics, lda_model_final.model, num_words=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Analyze topic modeling of individual messages\n",
    "\n",
    "Now, you can use the model as something like a multiclass classification model. Here you will analyze one message at a time, and determine how well it belongs to each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can select a category of messages and look into what topic the single message would be classified\n",
    "utils.interact_with_filters(utils.plot_random_message_classification, haiti_df, corpus_dictionary=corpus_dictionary, lda_topics=lda_model_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Topic importance as a function of time\n",
    "Plot the topic importance over time in the next cell. For each of the topics the importance is calculated in each week after the disaster. You can see that the importance of some topics increases with time while it decreases for other topics. Try to see if this makes sense based on the top words of each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_topic_importance(corpus_bow, haiti_df, lda_model_final, num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Removing additional words (optional)\n",
    "\n",
    "There are some words that are captured by the topic models as relevant because of their frequency, but are not really meaningful. In such cases, you can help the model by removing such words when you detect them. Examples of those words are 'like', 'would'. In the next cell you can include a list of words that the model must ignore. This is an important task where you can help the AI model. What other words do you identify? What do you think about 'please', 'need', and 'want'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can run this cell as many times as needed\n",
    "words_to_exclude = ['like', 'would']#, 'need', 'please'] # Add other words that you consider not important. \n",
    "print(f\"Before removal:\\nDictionary contains a total of {len(corpus_dictionary)} unique words\\n\")\n",
    "utils.exclude_words_from_dictionary(corpus_dictionary, words_to_exclude)\n",
    "\n",
    "# Create bag of words out of the full corpus\n",
    "corpus_bow = [corpus_dictionary.doc2bow(doc) for doc in corpus]\n",
    "# All words in the dictionary\n",
    "all_words = list(corpus_dictionary.values())\n",
    "print(f\"\\nAfter removal:\\nDictionary contains a total of {len(all_words)} unique words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you remove the words you can return back to step 6 and try how the models perform with some of the words removed. If you want to reset your dictionary and BOW, you can return to step 3 and run the cells there to restore them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional optional challenge / exploration\n",
    "\n",
    "**Look at topic modeling without removing any stopwords!**\n",
    "\n",
    "Run the cell below and then return to **step 3** above and run the cells in order to perform all the analysis in this lab without removing stopwords to see what you find. Here you'll read in the dataset again from scratch and then process the messages into tokens without removing stopwords. \n",
    "\n",
    "If you're a Python programmer, another thing you can try at this stage is looking at topic modeling for the other events captured in the dataset; Hurricane Sandy in the U.S. in 2012 or the Pakistan floods in 2010. You'll just need to change the filter below from `haiti_earthquake` to one of the other events, `usa_sandy` or `pakistan_floods`. But keep in mind the other events don't have dates associated with them so you'll need to comment out or modify any lines of code that are operating on the dates. \n",
    "\n",
    "Once you have loaded the data for a separate event, you'll have the option or training a new model for that event, or trying out your model trained on the Haiti data to see how it performs on another event. Try both if you're feeling ambitious and see what you find!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CHALLENGE / EXPLORATION: \n",
    "# Run the following lines of code to reload the data and tokenize without removing stopwords to see what happens\n",
    "# Load the datasets\n",
    "training_data = pd.read_csv(\"data/disaster_response_training.csv\", low_memory=False)\n",
    "validation_data = pd.read_csv(\"data/disaster_response_validation.csv\", low_memory=False)\n",
    "test_data = pd.read_csv(\"data/disaster_response_test.csv\", low_memory=False)\n",
    "# Merge the three datasets\n",
    "full_data = training_data.append(validation_data).append(test_data)\n",
    "# Fix column data type\n",
    "full_data['original'] = full_data['original'].astype(str)\n",
    "# Select only the Haiti data\n",
    "haiti_df = full_data[full_data.event == 'haiti_earthquake']\n",
    "# Fix column data type\n",
    "haiti_df['actionable_haiti'] = haiti_df.actionable_haiti.astype('int64')\n",
    "haiti_df['date_haiti'] = pd.to_datetime(haiti_df.date_haiti)\n",
    "# Get stopwords and punctuation from the utils file\n",
    "STOP_WORDS = [] #utils.STOP_WORDS\n",
    "punctuation = utils.punctuation\n",
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# Process all messages and save tokens to a new column\n",
    "haiti_df[\"message_tokens\"] = haiti_df.message.apply(\n",
    "    utils.process_text,\n",
    "    tokenizer=word_tokenize, pos_tagger=nltk.pos_tag, lemmatizer=lemmatizer, stopwords=STOP_WORDS, punctuation=punctuation\n",
    ")\n",
    "haiti_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
